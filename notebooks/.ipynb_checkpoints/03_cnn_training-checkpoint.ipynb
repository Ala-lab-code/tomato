{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f61900-4555-424e-8689-b4f09fa73d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN模型训练\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from src.data.dataset import create_dataloaders\n",
    "from src.models.resnet_se import ResNetSE\n",
    "from src.models.efficientnet_cbam import EfficientNetCBAM\n",
    "from src.training.trainer import Trainer\n",
    "from src.training.metrics import MetricsCalculator, FineGrainedMetrics\n",
    "from src.utils.visualization import plot_training_history\n",
    "from src.utils.logger import ExperimentTracker\n",
    "\n",
    "# 1. 设置\n",
    "DATA_DIR = \"/kaggle/input/plantvillage-tomato/PlantVillage/Tomato\"\n",
    "CONFIG_PATH = \"../configs/cnn.yaml\"\n",
    "OUTPUT_DIR = \"/kaggle/working/outputs/cnn\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 2. 检查GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Available memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# 3. 加载配置\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. 初始化实验跟踪器\n",
    "experiment_name = f\"CNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "tracker = ExperimentTracker(os.path.join(OUTPUT_DIR, experiment_name))\n",
    "tracker.log_config(config)\n",
    "\n",
    "# 5. 创建数据加载器\n",
    "print(\"Creating data loaders...\")\n",
    "train_loader, val_loader, test_loader, class_names = create_dataloaders(\n",
    "    DATA_DIR,\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    num_workers=config['data']['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "# 6. 创建模型\n",
    "print(\"\\nCreating model...\")\n",
    "model_type = config['model']['model_name']\n",
    "\n",
    "if model_type == 'resnet50_se':\n",
    "    model = ResNetSE(\n",
    "        num_classes=len(class_names),\n",
    "        pretrained=config['model']['pretrained']\n",
    "    )\n",
    "elif model_type == 'efficientnet_cbam':\n",
    "    model = EfficientNetCBAM(\n",
    "        num_classes=len(class_names),\n",
    "        pretrained=config['model']['pretrained']\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "print(f\"Model created: {model_type}\")\n",
    "tracker.log_message(f\"Model type: {model_type}\")\n",
    "\n",
    "# 7. 创建训练器\n",
    "print(\"\\nCreating trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    config=config,\n",
    "    class_names=class_names\n",
    ")\n",
    "\n",
    "# 8. 训练模型\n",
    "print(\"\\nStarting training...\")\n",
    "epochs = config['training']['epochs']\n",
    "history = trainer.train(epochs)\n",
    "\n",
    "# 9. 绘制训练历史\n",
    "print(\"\\nPlotting training history...\")\n",
    "fig_history = plot_training_history(history, figsize=(15, 10))\n",
    "history_path = os.path.join(tracker.log_dir, 'training_history.png')\n",
    "plt.savefig(history_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "tracker.log_artifact('figure', history_path, 'Training history plot')\n",
    "\n",
    "# 10. 测试模型\n",
    "print(\"\\nTesting model...\")\n",
    "test_results = trainer.test()\n",
    "\n",
    "# 11. 计算详细指标\n",
    "print(\"\\nComputing detailed metrics...\")\n",
    "metrics_calc = MetricsCalculator(len(class_names), class_names)\n",
    "detailed_metrics = metrics_calc.compute_metrics(\n",
    "    test_results['true_labels'],\n",
    "    test_results['predictions'],\n",
    "    test_results['probabilities']\n",
    ")\n",
    "\n",
    "# 记录指标\n",
    "tracker.log_metrics(detailed_metrics, \"test\")\n",
    "\n",
    "# 12. 细粒度分析\n",
    "print(\"\\nPerforming fine-grained analysis...\")\n",
    "fg_metrics = FineGrainedMetrics()\n",
    "\n",
    "# 分析相似类别混淆\n",
    "similar_classes = []\n",
    "for i, name_i in enumerate(class_names):\n",
    "    for j, name_j in enumerate(class_names):\n",
    "        if i < j:\n",
    "            # 基于名称相似性（如早疫病 vs 晚疫病）\n",
    "            if ('early' in name_i.lower() and 'late' in name_j.lower()) or \\\n",
    "               ('late' in name_i.lower() and 'early' in name_j.lower()):\n",
    "                similar_classes.append((i, j))\n",
    "\n",
    "if similar_classes:\n",
    "    confusion_results = fg_metrics.compute_similarity_confusion(\n",
    "        detailed_metrics['confusion_matrix'],\n",
    "        similar_classes\n",
    "    )\n",
    "    print(\"\\nSimilar class confusion analysis:\")\n",
    "    for pair, rate in confusion_results.items():\n",
    "        print(f\"  {pair}: {rate:.4f}\")\n",
    "    \n",
    "    tracker.log_metrics(confusion_results, \"fine_grained\")\n",
    "\n",
    "# 分析困难样本\n",
    "hard_samples = fg_metrics.analyze_hard_samples(\n",
    "    test_results['predictions'],\n",
    "    test_results['probabilities'],\n",
    "    test_results['true_labels'],\n",
    "    test_results['image_paths'],\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(\"\\nHard sample analysis saved\")\n",
    "\n",
    "# 13. 可视化结果\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "\n",
    "# 混淆矩阵\n",
    "fig_cm = metrics_calc.plot_confusion_matrix(\n",
    "    detailed_metrics['confusion_matrix'],\n",
    "    title=f'{model_type} - Confusion Matrix',\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "cm_path = os.path.join(tracker.log_dir, 'confusion_matrix.png')\n",
    "plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "tracker.log_artifact('figure', cm_path, 'Confusion matrix')\n",
    "\n",
    "# ROC曲线\n",
    "fig_roc = metrics_calc.plot_roc_curves(\n",
    "    test_results['true_labels'],\n",
    "    test_results['probabilities'],\n",
    "    figsize=(12, 10)\n",
    ")\n",
    "roc_path = os.path.join(tracker.log_dir, 'roc_curves.png')\n",
    "plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "tracker.log_artifact('figure', roc_path, 'ROC curves')\n",
    "\n",
    "# 预测结果可视化\n",
    "fig_pred = visualize_predictions(\n",
    "    test_results,\n",
    "    class_names,\n",
    "    num_samples=12,\n",
    "    figsize=(20, 15)\n",
    ")\n",
    "pred_path = os.path.join(tracker.log_dir, 'predictions.png')\n",
    "plt.savefig(pred_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "tracker.log_artifact('figure', pred_path, 'Prediction samples')\n",
    "\n",
    "# 14. 保存最佳模型\n",
    "best_model_path = os.path.join(tracker.log_dir, 'best_model.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': class_names,\n",
    "    'config': config,\n",
    "    'test_accuracy': detailed_metrics['accuracy']\n",
    "}, best_model_path)\n",
    "\n",
    "tracker.log_artifact('model', best_model_path, 'Best model checkpoint')\n",
    "\n",
    "# 15. 保存实验结果\n",
    "experiment_file = tracker.save_experiment()\n",
    "print(f\"\\nExperiment completed!\")\n",
    "print(f\"Test Accuracy: {detailed_metrics['accuracy']:.4f}\")\n",
    "print(f\"Results saved to: {tracker.log_dir}\")\n",
    "print(f\"Experiment file: {experiment_file}\")\n",
    "\n",
    "# 16. 模型比较（如果有多个模型）\n",
    "print(\"\\nGenerating model comparison...\")\n",
    "comparison_data = {\n",
    "    'Model': [model_type],\n",
    "    'Accuracy': [detailed_metrics['accuracy']],\n",
    "    'Precision': [detailed_metrics['precision']],\n",
    "    'Recall': [detailed_metrics['recall']],\n",
    "    'F1-Score': [detailed_metrics['f1']]\n",
    "}\n",
    "\n",
    "if 'roc_auc' in detailed_metrics:\n",
    "    comparison_data['ROC-AUC'] = [detailed_metrics['roc_auc']]\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# 保存比较结果\n",
    "comparison_path = os.path.join(tracker.log_dir, 'model_comparison.csv')\n",
    "df_comparison.to_csv(comparison_path, index=False)\n",
    "tracker.log_artifact('data', comparison_path, 'Model comparison CSV')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
