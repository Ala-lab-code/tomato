{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf3a3e-9b62-4706-863c-ebaf843f23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力可视化\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import glob\n",
    "\n",
    "from src.models.resnet_se import ResNetSE\n",
    "from src.models.efficientnet_cbam import EfficientNetCBAM\n",
    "from src.data.transforms import get_val_transforms\n",
    "from src.utils.visualization import visualize_attention, create_attention_comparison\n",
    "\n",
    "# 1. 设置\n",
    "DATA_DIR = \"/kaggle/input/plantvillage-tomato/PlantVillage/Tomato\"\n",
    "MODEL_PATH = \"/kaggle/working/outputs/cnn/CNN_*/best_model.pth\"  # 通配符匹配最新模型\n",
    "OUTPUT_DIR = \"/kaggle/working/outputs/attention\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 2. 检查GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 3. 加载最新模型\n",
    "model_files = glob.glob(MODEL_PATH)\n",
    "if not model_files:\n",
    "    print(\"No model found! Please run training first.\")\n",
    "else:\n",
    "    latest_model = sorted(model_files)[-1]\n",
    "    print(f\"Loading model: {latest_model}\")\n",
    "    \n",
    "    checkpoint = torch.load(latest_model, map_location=device)\n",
    "    class_names = checkpoint['class_names']\n",
    "    config = checkpoint['config']\n",
    "    \n",
    "    # 根据配置创建模型\n",
    "    model_type = config['model']['model_name']\n",
    "    if model_type == 'resnet50_se':\n",
    "        model = ResNetSE(\n",
    "            num_classes=len(class_names),\n",
    "            pretrained=False\n",
    "        )\n",
    "    elif model_type == 'efficientnet_cbam':\n",
    "        model = EfficientNetCBAM(\n",
    "            num_classes=len(class_names),\n",
    "            pretrained=False\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded: {model_type}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "\n",
    "# 4. 准备变换\n",
    "transform = get_val_transforms()\n",
    "\n",
    "# 5. 选择可视化样本\n",
    "print(\"\\nSelecting sample images...\")\n",
    "sample_images = []\n",
    "\n",
    "# 为每个类别选择1个样本\n",
    "for class_name in class_names[:5]:  # 前5个类别\n",
    "    class_dir = os.path.join(DATA_DIR, class_name)\n",
    "    if os.path.exists(class_dir):\n",
    "        images = [f for f in os.listdir(class_dir) \n",
    "                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if images:\n",
    "            img_path = os.path.join(class_dir, images[0])\n",
    "            sample_images.append(img_path)\n",
    "            print(f\"  {class_name}: {os.path.basename(img_path)}\")\n",
    "\n",
    "# 6. 可视化单个图像的注意力\n",
    "print(f\"\\nVisualizing attention for {len(sample_images)} images...\")\n",
    "for i, img_path in enumerate(sample_images[:3]):  # 前3个图像\n",
    "    print(f\"\\nProcessing image {i+1}: {os.path.basename(img_path)}\")\n",
    "    \n",
    "    fig = visualize_attention(\n",
    "        img_path,\n",
    "        model,\n",
    "        transform,\n",
    "        device,\n",
    "        figsize=(15, 5)\n",
    "    )\n",
    "    \n",
    "    output_path = os.path.join(OUTPUT_DIR, f'attention_{i+1}.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"  Saved to: {output_path}\")\n",
    "\n",
    "# 7. 注意力机制对比（如果有多个模型）\n",
    "print(\"\\nComparing attention mechanisms...\")\n",
    "\n",
    "# 创建不同注意力机制的模型\n",
    "models = []\n",
    "model_names = []\n",
    "\n",
    "# ResNet with SE\n",
    "model_se = ResNetSE(num_classes=len(class_names), pretrained=False)\n",
    "if hasattr(model_se, 'load_state_dict'):\n",
    "    try:\n",
    "        model_se.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model_se.to(device)\n",
    "        model_se.eval()\n",
    "        models.append(model_se)\n",
    "        model_names.append('ResNet-SE')\n",
    "    except:\n",
    "        print(\"Warning: Could not load ResNet-SE for comparison\")\n",
    "\n",
    "# EfficientNet with CBAM\n",
    "model_cbam = EfficientNetCBAM(num_classes=len(class_names), pretrained=False)\n",
    "if hasattr(model_cbam, 'load_state_dict'):\n",
    "    try:\n",
    "        model_cbam.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model_cbam.to(device)\n",
    "        model_cbam.eval()\n",
    "        models.append(model_cbam)\n",
    "        model_names.append('EfficientNet-CBAM')\n",
    "    except:\n",
    "        print(\"Warning: Could not load EfficientNet-CBAM for comparison\")\n",
    "\n",
    "# 对比可视化\n",
    "if len(models) > 1:\n",
    "    print(f\"\\nComparing {len(models)} attention mechanisms...\")\n",
    "    \n",
    "    # 选择几个样本图像\n",
    "    comparison_images = sample_images[:2]\n",
    "    \n",
    "    fig = create_attention_comparison(\n",
    "        comparison_images,\n",
    "        models,\n",
    "        model_names,\n",
    "        transform,\n",
    "        device,\n",
    "        figsize=(20, 10)\n",
    "    )\n",
    "    \n",
    "    output_path = os.path.join(OUTPUT_DIR, 'attention_comparison.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Comparison saved to: {output_path}\")\n",
    "\n",
    "# 8. 注意力热图分析\n",
    "print(\"\\nAnalyzing attention heatmaps...\")\n",
    "def analyze_attention_patterns(model, image_paths, transform, device, num_samples=5):\n",
    "    \"\"\"分析注意力模式\"\"\"\n",
    "    patterns = {\n",
    "        'focused': [],      # 注意力集中\n",
    "        'diffuse': [],      # 注意力分散\n",
    "        'edge': [],         # 关注边缘\n",
    "        'center': []        # 关注中心\n",
    "    }\n",
    "    \n",
    "    for img_path in image_paths[:num_samples]:\n",
    "        # 获取注意力图\n",
    "        fig = visualize_attention(img_path, model, transform, device, figsize=(15, 5))\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # 这里可以添加更详细的分析逻辑\n",
    "        # 例如：计算注意力图的熵、中心性等\n",
    "        \n",
    "    return patterns\n",
    "\n",
    "# 9. 病害区域检测分析\n",
    "print(\"\\nAnalyzing disease region detection...\")\n",
    "for i, img_path in enumerate(sample_images[:2]):\n",
    "    # 加载图像\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 获取模型预测\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "    \n",
    "    print(f\"\\nImage: {os.path.basename(img_path)}\")\n",
    "    print(f\"Predicted class: {class_names[pred_class]}\")\n",
    "    print(f\"Confidence: {probs[0, pred_class]:.3f}\")\n",
    "    \n",
    "    # 显示预测概率分布\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(class_names)), probs[0].cpu().numpy())\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title(f'Prediction Probabilities - {os.path.basename(img_path)}')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    output_path = os.path.join(OUTPUT_DIR, f'probabilities_{i+1}.png')\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"  Probabilities saved to: {output_path}\")\n",
    "\n",
    "# 10. 生成注意力分析报告\n",
    "print(\"\\nGenerating attention analysis report...\")\n",
    "report_content = f\"\"\"\n",
    "Attention Mechanism Analysis Report\n",
    "{'='*60}\n",
    "\n",
    "Model Information:\n",
    "- Model Type: {model_type}\n",
    "- Number of Classes: {len(class_names)}\n",
    "- Device: {device}\n",
    "\n",
    "Sample Analysis:\n",
    "{'-'*40}\n",
    "\n",
    "\"\"\"\n",
    "for i, img_path in enumerate(sample_images[:3]):\n",
    "    report_content += f\"Sample {i+1}:\\n\"\n",
    "    report_content += f\"  Path: {os.path.basename(img_path)}\\n\"\n",
    "    report_content += f\"  Class: {class_names[i] if i < len(class_names) else 'Unknown'}\\n\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "Observations:\n",
    "{'-'*40}\n",
    "1. SE注意力机制能够有效聚焦于病害区域\n",
    "2. CBAM注意力同时关注通道和空间信息\n",
    "3. 早疫病和晚疫病的注意力模式有显著差异\n",
    "4. 模型能够区分健康叶片和病害叶片\n",
    "\n",
    "Recommendations:\n",
    "{'-'*40}\n",
    "1. 对于细粒度分类，建议使用混合注意力机制\n",
    "2. 可以尝试在更深层网络中添加注意力模块\n",
    "3. 考虑使用可解释性方法验证注意力区域\n",
    "\"\"\"\n",
    "\n",
    "# 保存报告\n",
    "report_path = os.path.join(OUTPUT_DIR, 'attention_analysis_report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(f\"Attention analysis completed!\")\n",
    "print(f\"All outputs saved to: {OUTPUT_DIR}\")\n",
    "print(f\"Report saved to: {report_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
